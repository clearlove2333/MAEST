{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/STexp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: /zhupengfei/STExperiment/MAEST/plot/Mouse_HT\n",
      "新的工作目录: /zhupengfei/STExperiment/MAEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_99088/2543689245.py:36: DeprecationWarning: Please use `csc_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csc` namespace is deprecated.\n",
      "  from scipy.sparse.csc import csc_matrix\n",
      "/tmp/ipykernel_99088/2543689245.py:37: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  from scipy.sparse.csr import csr_matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/opt/conda/envs/STexp/lib/python3.10/site-packages/ipykernel_launcher.py'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import dgl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# sys.path.append('/zhupengfei/STExperiment/MAEST/')\n",
    "# 获取当前工作目录\n",
    "current_directory = os.getcwd()\n",
    "print(f\"当前工作目录: {current_directory}\")\n",
    " \n",
    "# 修改当前工作目录\n",
    "new_directory = '/zhupengfei/STExperiment/MAEST/'\n",
    "os.chdir(new_directory)\n",
    " \n",
    "# 再次获取当前工作目录以确认更改\n",
    "current_directory = os.getcwd()\n",
    "print(f\"新的工作目录: {current_directory}\")\n",
    "\n",
    "from utils import (\n",
    "    build_args,\n",
    "    create_optimizer,\n",
    "    set_random_seed,\n",
    "    TBLogger,\n",
    "    get_current_lr,\n",
    "    load_best_configs,\n",
    "    build_args_known,\n",
    ")\n",
    "from models import build_model\n",
    "from process.function import Function\n",
    "import scanpy as sc\n",
    "from process.preprocess import preprocess_adj, preprocess_adj_sparse, preprocess, construct_interaction, construct_interaction_KNN, get_feature\n",
    "from scipy.sparse.csc import csc_matrix\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "\n",
    "# 获取当前运行的脚本文件名\n",
    "script_name = sys.argv[0]\n",
    " \n",
    "# 获取脚本的完整路径\n",
    "script_path = os.path.realpath(script_name)\n",
    "\n",
    "script_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 16:25:33,869 - INFO - ----- Using best configs from configs/Mouse_HT.yaml -----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Namespace(seeds=[41], dataset='Mouse_HT', device=0, max_epoch=900, warmup_steps=-1, num_heads=8, num_out_heads=1, num_layers=1, num_dec_layers=1, num_remasking=3, num_hidden=1024, residual=False, in_drop=0.1, attn_drop=0.1, norm=None, lr=0.001, weight_decay=0.0002, negative_slope=0.2, activation='prelu', mask_rate=0.3, remask_rate=0.5, remask_method='random', mask_type='mask', mask_method='random', drop_edge_rate=0.0, encoder='gat', decoder='gat', loss_fn='sce', alpha_l=3, optimizer='adam', no_pretrain=False, load_model=False, use_cfg=True, logging=False, scheduler=True, lam=0.2, delayed_ema_epoch=0, replace_rate=0.05, momentum=0, sample=['151673'], bet=0.02, power=2, self_loop=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#加载args\n",
    "the_args = ['--device', '0', '--dataset', 'Mouse_HT', '--mask_method', \"random\", '--remask_method', \"random\", '--alpha_l',\n",
    "             '3', '--scheduler', '--seeds', '41', '--use_cfg']\n",
    "\n",
    "args = build_args_known(the_args)\n",
    "if args.use_cfg:\n",
    "    args = load_best_configs(args)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所用GPU为: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mouse_HT'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#基础设置\n",
    "device = args.device if args.device >= 0 else \"cpu\"\n",
    "print(\"所用GPU为:\",device)\n",
    "seed = args.seeds[0]\n",
    "dataset = args.dataset\n",
    "max_epoch = args.max_epoch\n",
    "num_hidden = args.num_hidden\n",
    "num_layers = args.num_layers\n",
    "encoder_type = args.encoder\n",
    "decoder_type = args.decoder\n",
    "replace_rate = args.replace_rate\n",
    "optim_type = args.optimizer\n",
    "loss_fn = args.loss_fn\n",
    "lr = args.lr\n",
    "weight_decay = args.weight_decay\n",
    "# save_model = args.save_model\n",
    "logs = args.logging\n",
    "use_scheduler = args.scheduler\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点数 <bound method DGLGraph.number_of_nodes of Graph(num_nodes=53208, num_edges=319248,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})>\n",
      "未加自环 <bound method DGLGraph.number_of_edges of Graph(num_nodes=53208, num_edges=319248,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})>\n",
      "已加自环 <bound method DGLGraph.number_of_edges of Graph(num_nodes=53208, num_edges=372456,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})>\n"
     ]
    }
   ],
   "source": [
    "result_path = Path('./results/' + f'{dataset}/')\n",
    "# result_path.mkdir(parents=True, exist_ok=True)\n",
    "#初始化模型\n",
    "function = Function(datatype=dataset, n_clusters=10)\n",
    "adata = function.loadData()\n",
    "adata, u, v = function.process(adata)\n",
    "#创建dgl数据\n",
    "graph = dgl.graph((torch.tensor(u + v), torch.tensor(v + u)))\n",
    "print(\"节点数\", graph.number_of_nodes)\n",
    "print(\"未加自环\", graph.number_of_edges)\n",
    "if(args.self_loop):\n",
    "    graph = dgl.add_self_loop(graph)\n",
    "    print(\"已加自环\", graph.number_of_edges)\n",
    "x = torch.tensor(adata.obsm['feat'])\n",
    "args.num_features = x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(seed)\n",
    "if logs:\n",
    "    logger = TBLogger(\n",
    "        name=f\"{dataset}_loss_{loss_fn}_rpr_{replace_rate}_nh_{num_hidden}_nl_{num_layers}_lr_{lr}_mp_{max_epoch}_mpf_{max_epoch_f}_wd_{weight_decay}_wdf_{weight_decay_f}_{encoder_type}_{decoder_type}\")\n",
    "else:\n",
    "    logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Use sce_loss and alpha_l=3 ===\n",
      "num_encoder_params: 3075072, num_decoder_params: 3081000, num_params_in_total: 8783842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreModel(\n",
       "  (encoder): GAT(\n",
       "    (gat_layers): ModuleList(\n",
       "      (0): GATConv(\n",
       "        (fc): Linear(in_features=3000, out_features=1024, bias=False)\n",
       "        (feat_drop): Dropout(p=0.1, inplace=False)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (decoder): GAT(\n",
       "    (gat_layers): ModuleList(\n",
       "      (0): GATConv(\n",
       "        (fc): Linear(in_features=1024, out_features=3000, bias=False)\n",
       "        (feat_drop): Dropout(p=0.1, inplace=False)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (encoder_to_decoder): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "  (projector): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (1): PReLU(num_parameters=1)\n",
       "    (2): Linear(in_features=256, out_features=1024, bias=True)\n",
       "  )\n",
       "  (projector_ema): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (1): PReLU(num_parameters=1)\n",
       "    (2): Linear(in_features=256, out_features=1024, bias=True)\n",
       "  )\n",
       "  (predictor): Sequential(\n",
       "    (0): PReLU(num_parameters=1)\n",
       "    (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (encoder_ema): GAT(\n",
       "    (gat_layers): ModuleList(\n",
       "      (0): GATConv(\n",
       "        (fc): Linear(in_features=3000, out_features=1024, bias=False)\n",
       "        (feat_drop): Dropout(p=0.1, inplace=False)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
       "      )\n",
       "    )\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (discrimination_loss): BCEWithLogitsLoss()\n",
       "  (DGI_projector): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): PReLU(num_parameters=1)\n",
       "    (2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (3): PReLU(num_parameters=1)\n",
       "    (4): Linear(in_features=128, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建模型\n",
    "model = build_model(args)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #加载模型\n",
    "# if args.load_model:\n",
    "#     model.load_state_dict(torch.load(\"./saved_models/MAEST_\" + args.dataset + \".pt\"))\n",
    "#     ari=function.clusting(adata, model, graph, x, args.power, device)\n",
    "#     print(ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 16:33:10,569 - INFO - Use schedular\n"
     ]
    }
   ],
   "source": [
    "optimizer = create_optimizer(optim_type, model, lr, weight_decay)\n",
    "\n",
    "if use_scheduler:\n",
    "    logging.info(\"Use schedular\")\n",
    "    scheduler = lambda epoch: (1 + np.cos((epoch) * np.pi / max_epoch)) * 0.5\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=scheduler)\n",
    "else:\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 16:35:22,661 - INFO - start training..\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"start training..\")\n",
    "graph = graph.to(args.device)\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch 86: train_loss: 1.4680:  10%|▉         | 87/900 [01:03<09:53,  1.37it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem()}\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/STexp/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/STexp/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# target_nodes = torch.arange(x.shape[0], device=x.device, dtype=torch.long)\n",
    "epoch_iter = tqdm(range(max_epoch))\n",
    "for epoch in epoch_iter:\n",
    "# for epoch in range(max_epoch):\n",
    "    model.train()\n",
    "    loss = model(graph, x)\n",
    "\n",
    "    loss_dict = {\"loss\": loss.item()}\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    epoch_iter.set_description(f\"# Epoch {epoch}: train_loss: {loss.item():.4f}\")\n",
    "    if logger is not None:\n",
    "        loss_dict[\"lr\"] = get_current_lr(optimizer)\n",
    "        logger.note(loss_dict, step=epoch)\n",
    "\n",
    "    # if (epoch + 1) % 100 == 0:\n",
    "    #     #聚类\n",
    "    #     function.clusting_no_label(adata, model, graph, x, power, device)\n",
    "\n",
    "    #     # plotting spatial clustering result\n",
    "    #     plt.rcParams[\"figure.figsize\"] = (5, 5)\n",
    "\n",
    "    #     fig, ax = plt.subplots()\n",
    "    #     fig.subplots_adjust(left=0.02, right=0.82)  # 调整左边缘的边距\n",
    "\n",
    "    #     sc.pl.embedding(adata, \n",
    "    #                     basis=\"spatial\", \n",
    "    #                     color=\"domain\",\n",
    "    #                     s=4, \n",
    "    #                     show=False, \n",
    "    #                     title='Mouse Olf',\n",
    "    #                     ax=ax\n",
    "    #                     )\n",
    "    #     plt.axis('off')\n",
    "\n",
    "        # plt.savefig(\"./results/\" + dataset + \"/\" + str(epoch) + \".png\")\n",
    "        # adata.write(\"./results/\" + dataset + \"/\" + str(epoch) +\".h5ad\")\n",
    "        # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes_list=['ATP2B4', 'RASGRF2', 'LAMP5', 'NEFH', 'NTNG2', 'B3GALT2']\n",
    "ax = sc.pl.stacked_violin(adata, marker_genes_list,\n",
    "                          groupby='ground_truth', swap_axes=False, dendrogram=False, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gene = 'B3GALT2'\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "sc.pl.spatial(adata, img_key=\"hires\", color=plot_gene, show=False, ax=axs[0], title='RAW_'+plot_gene, vmax='p99')\n",
    "sc.pl.spatial(adata, img_key=\"hires\", color=plot_gene, show=False, ax=axs[1], title='STAGATE_'+plot_gene, layer='MAEST', vmax='p99')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(adata, color=marker_genes_list, ncols=2, cmap='Spectral_r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
